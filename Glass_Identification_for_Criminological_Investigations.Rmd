---
title: "Practice1"
author: "Umaimah Ahmed"
date: 2025-03-06
output: 
  pdf_document:
    fig_height: 3
    fig_width: 5
editor_options: 
  chunk_output_type: inline
---

```{r, include = FALSE}
library(mosaic)
options(digits = 6)
library(caret)
library(recipes)
library(ggplot2)
library(GGally)
library(gbm)
library(rsample)

# add other packages you need here
library(tidyverse)
library(ranger)
```

The overall assignment is due by midnight, Thursday, March 6th to Gradescope. The intermediate part of the assignment - see separate checklist and instructions - is due by midnight, Thursday, Feb. 27th to Gradescope. 



# Practicing Academic Integrity

If you worked with others or used resources outside of provided course material (anything besides our textbook(s), course materials in Moodle, R help menu) to complete this assignment, please acknowledge them below using a bulleted list. Generative AI is not permitted for our course. 

<!-- ~~~~~~~~~~~~~~~~ YOU MAY BEGIN EDITING BELOW THIS LINE ~~~~~~~~~~~~~~~~ -->

*I acknowledge the following individuals with whom I worked on this assignment:*

Name(s) and corresponding problem(s)

*

*I used the following sources to help complete this assignment:*

Source(s) and corresponding problem(s)

* 

\newpage

# Prompt

The study of classification of types of glass was motivated by criminological investigation. At the scene of the crime, the glass left can be used as evidence...if it is correctly identified! (Spiehler 1987) It turns out that glass isn't always easily identifiable. In order to help criminologists classify glass, data was gathered in order to allow for analysis and development of appropriate models. 

Note that the variable ID is NOT a variable that should be used in the classification. It is just the observation number. It is removed for you below. 

Data Description from source:   
  1. ID number (should not be used in the analysis)  
   2. RI: refractive index  
   3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 3-10)  
   4. Mg: Magnesium  
   5. Al: Aluminum  
   6. Si: Silicon  
   7. K: Potassium  
   8. Ca: Calcium  
   9. Ba: Barium  
   10. Fe: Iron  
  11. Type of glass: (class attribute)  
      -- 1 building_windows_float_processed  
      -- 2 building_windows_non_float_processed  
      -- 3 vehicle_windows_float_processed  
      -- 4 vehicle_windows_non_float_processed     
      -- 5 containers  
      -- 6 tableware  
      -- 7 headlamps  
      
Your task is to explore the data set and propose at least 3 classification models (from different techniques; at least one tree-based technique and at least one non-tree-based technique must be used, a total of (at least) 3 different techniques must be used) to classify the glass for the criminologists. Then, you must provide a final model with appropriate support for why it is the best model to use. 

There is some flexibility with how you *orient* yourself to the problem. For example, if you want to focus on building models that might be easily explainable in court cases for evidence, you might take a different approach than someone who is not concerned about that. You get to discuss your choice/understanding of the problem in the introduction. 

Audience: Remember in the methods section that your audience has covered all the methods before classification, so you don't need to re-explain CV, etc. But they need an explanation of the classification methods you are using. The audience is not (necessarily) the criminologists, but a statistically literate audience. 

\newpage

## Introduction 

```{r, include = FALSE}
# Do not put anything in this chunk. It is for instructions only.
# It will not show up in your rendered pdf document.

# You should provide your own brief introduction to the problem at hand. 
# The intro section should be you restating the problem in your own words, 
# with relevant context. From the intro, a reader should know what you understand
# the problem to be, how you plan to tackle it, and broadly, what data you have
# to work with (data details in the next section).
```

The classification of glass types plays an important role in forensic investigations, where correctly identifying glass fragments found at crime scenes can provide valuable evidence. However, distinguishing between different types of glass can prove to be difficult. To assist criminologists in making accurate classifications, this study explores three different classification methods to find an effective and efficient model that will categorize glass samples into one of six types of glass based on key attributes such as refractive index or chemical make-up. We will use two tree-based modeling techniques (random forest and gradient boosting), and one non-tree-based method (neural nets). Our aim is to find a model that balances accuracy and efficiency, aiding criminologists and forensic teams in analyzing future glass samples. 

\newpage

## Data

```{r, include = FALSE}
# Do not put anything in this chunk. It is for instructions only.
# It will not show up in your rendered pdf document.

# Introduce the reader to the data set. 
# You should describe what you know about the data set. 

# Then, you need to engage in EDA and any pre-processing that needs done before
# you can implement the necessary methods to tackle the analysis itself. 
# All those steps/decisions should be described here. 

# Specific things to think about for classification.

# What do you learn about the response variable? How many classes do you have?
# Are any classes small? Is there major class imbalance?
```

**Missing Data and ZV/NZV** 

The glass data set had 214 observations with 10 variables relevant to our analysis. There were 9 quantitative predictor variables and 1 categorical variable, which was the response we aimed to predict. The predictor variables are as follows:

* `RI`, the refractive index of the glass,
* `Na`, the weight percent of sodium in the glass sample,
* `Mg`, the weight percent of magnesium,
* `Al`, the weight percent of aluminum,
* `Si`, the weight percent of silicon,
* `K`, the weight percent of potassium,
* `Ca`, the weight percent of calcium,
* `Ba`, the weight percent of barium, and
* `Fe`, the weight percent of iron,

The response variable, `Type` had 7 possible levels, 

      -- 1 building_windows_float_processed  
      -- 2 building_windows_non_float_processed  
      -- 3 vehicle_windows_float_processed  
      -- 4 vehicle_windows_non_float_processed    
      -- 5 containers  
      -- 6 tableware  
      -- 7 headlamps

We started by processing the data. We made sure the response variable, `Type`, was coded in a way that allows us to do analysis. We also removed the `ID` variable because it's just for identification and unnecessary for the rest of our analysis.

```{r}
glass <- read.table("https://awagaman.people.amherst.edu/stat240/glass.txt", 
                    h = T, sep = ",")
glass <- mutate(glass, Type = paste("Type", Type, sep=""))
glass <- mutate(glass, Type = factor(Type)) %>% 
  dplyr::select(-ID) #removes ID
```


First we checked the data set to see if there was any missingness or any zero/near-zero variance variables.

```{r}
# visualization of missing data
visdat::vis_miss(glass, cluster = TRUE)

# checking variance
caret::nearZeroVar(glass, saveMetrics = TRUE) %>%
tibble::rownames_to_column() %>%
filter(nzv)
```
There were no missing values. None of the variables appeared to have zero or near-zero variance.

**Exploratory Data Analysis** 

```{r, message=FALSE, warning=FALSE}
### response variable ###
# distribution of classes
tally(~Type, data = glass, format = "count")
n <- nrow(glass)
(n-76)/n
1-(n-76)/n 
```

There are six types of glass in our analysis: float glass building window (70), non-float glass building window (76), float glass vehicle window (17), non-float glass vehicle window (0), containers (13), tableware (9), headlamps (29). Although non-float glass vehicle window was present as a level for the Type variable, there weren't any observations for that level.
It looks like there's some serious class imbalance. We'll have to stratify by Type when we split the data to make sure no class is lost.

The misclassification error rate if we classified every observation as the most prevalent type of glass, non-float building window glass, would be 0.6449. In other words, our baseline AER (apparent error rate) is $1-0.6449 = 0.3551$. We aim to develop a model with an AER lower than .3551.

```{r, fig.width=6, fig.height=4}
# longer data 
glass_long <- glass %>%
  pivot_longer(cols = c(RI, Na, Mg, Al, Si, K, Ca, Ba, Fe), 
               names_to = "predictor", values_to = "value")

# Create density plot
ggplot(glass_long, aes(x = value)) +
  geom_density(aes(fill = predictor)) +
  facet_wrap(~ predictor, scales = "free") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5)) +
  labs(title = "Density Plots of Predictors", x = "Value", y = "Density")
```

Taking a look at the distributions of the predictor variables, many of them do not appear to be normally distributed. Several of them, `K`, `Ba`, and `Fe` appear to be heavily skewed.


\newpage

## Methods

```{r, include = FALSE}
# Do not put anything in this chunk. It is for instructions only.
# It will not show up in your rendered pdf document.

# The idea here is to outline what methods the reader will see applied next 
# and why you chose them, as well as how you are setting any options that they
# have in order to do the analysis. 

########### my notes ############
# random forest, neural nets, gradient boosting perhaps
```

Next, we set up our training and test sets, and our cross validation process. To train and test our models and tune hyperparameters, we split the data set with a 75/25 split. We chose this ratio so that there are a sufficient number of observations in the test set while still giving the model enough data to be trained on. We also made sure to stratify the training and test sets by class to maintain similar distributions for `Type`, our reponse variable. During our exploratory data analysis, we noted that there were some very small classes in the response variable, so another reason to stratify was to make sure we didn't lose any classes in the training or test sets.
With a smaller data set, we also decided it would be appropriate to do repeated CV; for the models in this study we used 10-fold cross validation repeated 5 times. Cross validation is necessary for hyperparameter tuning (which we will explain in more detail later), allowing us to tweak our model to find appropriate settings to lower rates of misclassification.


```{r}
# splitting data
set.seed(240)
split <- initial_split(glass, prop = 0.75, strata = "Type")
glass_train <- training(split)
glass_test <- testing(split)
```

```{r}
# CV setup
glass_control <- trainControl(
  method = "repeatedcv", 
  number = 10, 
  repeats = 5,
  classProbs = TRUE)
```

  We will be applying feature engineering with the `recipes` package in `R`. We will start by making a recipe that applies necessary pre-processing steps based on what the classification method requires. Then, it will be prepped on the training set, estimating the parameters needed to properly apply the recipe blueprint. With the recipe prepped, we can bake it onto the training and test sets.

  For the classification methods we applied, it was necessary to create two recipe blueprints. Different methods can require different pre-processing steps, and it is important to prepare the training and test sets for models to be fit on them. For our tree-based methods, random forest and gradient boosting, minimal pre-processing was required. In the Data section we saw that there were no zero or near-zero variance variables, so we are able to set the recipe for the tree methods as-is. For kNN, a method that is sensitive to scale, it was necessary for us to standardize the data before training the kNN model.

```{r}
# recipe used for trees
bp_tree <- recipe(Type ~ ., data = glass_train)

# recipe used for knn
bp_scale <- recipe(Type ~ ., data = glass_train) %>% 
  step_center(all_numeric(), -all_outcomes()) %>%
  step_scale(all_numeric(), -all_outcomes())
```

  To compare models and measure performance, we will compare the both the apparent error rate (AER) and estimated true error rate (TER) of each proposed model.The AER, calculated directly from the training data, provides an initial assessment of model accuracy but tends to be overly optimistic due to potential over-fitting. To obtain a more reliable estimate, we compute the TER, which better reflects the model’s expected performance on unseen data.

  This study tests two tree-based classification models and one non-tree based classification model to find the method that best classifies the crime-scene glass data.The only non-tree method we used in this study was the method of $k$-nearest neighbors. $K$-nearest neighbors, or KNN, is a nonparametric method that classifies data based on the data points most similar to it. For each observation, we find a specified $k$ number of observations nearest to it. Although there are several different ways to measure what is "nearest," for this study we used Euclidean distance. Observations are classified to the majority class of the nearest neighbors. For KNN, standardization is a necessary step in pre-processing the data, as distance measurements are sensitive to scale. The only hyperparameter we have to worry about tuning is $k$, the number of neighbors. KNN can become computationally inefficient with larger data sets but for glass classification in this study, with a relatively low number of observations and only nine predictors, it took only a few minutes to run. Additionally, KNN is rather intuitive, which may prove beneficial when potentially presenting this model in a court as evidence.
  
  The next classification method we employed was random forest. Random forest is a type of ensemble method that improves on the instability of decision trees by aggregating multiple trees. It also addresses the greediness of trees by limiting the number of predictors that can be used. Random forest involves first bootstrapping $B$ samples from the data set, and a tree is made from each bootstrapped sample. The best split for each step is chosen at random from a subset of $m_{try}$ predictors. The hyperparameters we tuned for the random forest model were $m_{try}$ and the minimum node size, which dictates what the size of the smallest node in each tree can be.

  The last model is a gradient boosting model, or GBM. Like random forest, gradient boosting is another technique that works by building an ensemble of decision trees. It improves on each tree iteratively, minimizing error by improving where the previous tree fells short. Each new tree thereby "boosts" performance. Boosting starts with a base learner, which was a decision tree in this study, but boosting is a framework that can be used for any weak learner. The base learners start weak and are trained sequentially by targeting rows of data where the previous tree had the largest errors. The learning rate decides the size of the step the boost will take to improve the previous tree. Although a small learning rate will likely lead to higher accuracy, if its *too* small, then the algorithm becomes computationally cumbersome and will take too long to find the minimum gradient. If the learning rate is too big, then it might jump past the minimum gradient and leave us with a tree that doesn't perform very well. The hyperparameters we tuned for this model were the depth of the individual trees and the minimum node size.
  
  Hyperparameter tuning is an important step in the process of building a strong classification model, altering how the model is trained and how well is generalizes to new data. Tuning allows us to find the best combination of hyperparameters that reduces error and improves predictive power. In order to test several hyperparameter combinations, we create hyperparameter grids to perform grid searches. The grid helps us optimize hyperparameter tuning. For random forest, we tried values of $m_{try}$ 1 through 9 (classifying with only one predictor variable, all the way up to all predictor variables), and a minimum node size of 1, 2, 6, 8. For gradient boosting, we held the number of trees constant at 500, the shrinkage rate constant at 0.05, but tested interaction depths of 8, 10 and 15, and minimum node sizes of 8, 6, and 10. For kNN we tried several values of $k$ from 1 through 40. For each classification method, the hyperparameter combination that resulted in the model with with the highest cross validated accuracy was saved to compare accross all methods.

```{r}
# for random forest
glass_rfgrid <- expand.grid(
  mtry = 2:9, 
  splitrule = "gini",
  min.node.size = c(2, 4, 5, 6))

# for gradient boosting
glass_boostgrid <- expand.grid(
  n.trees = 1000,
  shrinkage = 0.05,
  interaction.depth = c(8, 10, 15, 20),
  n.minobsinnode = c(4, 6, 8, 10))

# for knn
glass_knngrid <- expand.grid(
  k = seq(1, 41, by = 4))
```


\newpage


## Results 

```{r, include = FALSE}
# Do not put anything in this chunk. It is for instructions only.
# It will not show up in your rendered pdf document.

# Apply the methods (show your work) and describe what you find. 
# Describe/show the path you took and how you arrived at your final analysis
# and give details in depth for the main techniques/models you are comparing. 

# For classification, you may have multiple models within a technique 
# that are compared + then a comparison of the best models from each 
# technique. Up to you to present your analysis trajectory, and you 
# determine what you show versus not. 
```


**Fitting our Models**

We start with a grid search for the $k$ parameter in our KNN model.

```{r}
# fitting knn
set.seed(240)
glass_knntune <- train(
  bp_scale,
  data = glass_train,
  method = "knn",
  trControl = glass_control,
  tuneGrid = glass_knngrid)

ggplot(glass_knntune) +
  labs(title = "K Nearest Neighbors Hyperparameter Tuning Results",
       x = "Number of Neighbors",
       y = "Accuracy (Repeated CV)") +
  theme_minimal()
glass_knntune

# aer
1-0.688382
```
The KNN model that used $k=1$ had the lowest error rate, with an AER of 0.312. While this is better than our benchmark misclassification error of 0.353, it's not much of an improvement.

Next we do a grid search for the random forest model.
```{r, cache=TRUE}
# fitting random forest
set.seed(240) # for reproducibility
glass_rftune <- train(
  bp_tree,
  data = glass_train,
  method = "ranger",
  trControl = glass_control,
  tuneGrid = glass_rfgrid)

ggplot(glass_rftune) +
  labs(title = "Random Forest Hyperparameter Tuning Results",
       x = "Number of Randomly Selected Predictors",
       y = "Accuracy (Repeated CV)") +
  theme_minimal()
glass_rftune

# aer
1-0.774468
```
It appears that our best random forest model used 5 randomly selected predictors and a minimum node size of 4. The AER for the random forest was 0.226. 

```{r, warning=FALSE, message=FALSE}
# gradient boosting
set.seed(240)
glass_boosttune <- train(
  bp_tree,
  data = glass_train,
  method = "gbm",
  trControl = glass_control,
  tuneGrid = glass_boostgrid,
  verbose = FALSE)

ggplot(glass_boosttune) +
  labs(title = "Gradient Boosting Hyperparameter Tuning Results",
       x = "Tree Depth",
       y = "Accuracy (Repeated CV)") +
  theme_minimal()
glass_boosttune

1-0.758666
```
With the number of trees and shrinkage rate held constant at 1000 and 0.05 respectively, the best boosting model an interaction depth of 8 and a minimum node size of 8. The cross validated AER was 0.241.

**Model Performance**

```{r}
# Extract out of sample performance measures
summary(resamples(list(
  model1 = glass_knntune,
  model2 = glass_rftune,
  model3 = glass_boosttune)))
```

If we recall the average cross validated accuracies of each model, it appeared that random forest was performing the best out of the three proposed models. We want to see how the models perform when tested against the training set and compare the AER of each model.

```{r}
### aer
# knn
glass_train_pred_knn <- predict(glass_knntune, glass_train)
confusionMatrix(glass_train_pred_knn, glass_train$Type)

# random forest
glass_train_pred_rf <- predict(glass_rftune, glass_train)
confusionMatrix(glass_train_pred_rf, glass_train$Type)

# gradient boosting
glass_train_pred_gb <- predict(glass_boosttune, glass_train)
confusionMatrix(glass_train_pred_gb, glass_train$Type)
```

Just based on the AER, we can't tell which model performed the best. All three models performed extremely well on the training set. So, we decided to take the a look at the estimated true error rate, the TER. We estimate the true error by testing the model against the test set.

```{r}
### ter
# knn
glass_test_pred_knn <- predict(glass_knntune, glass_test)
confusionMatrix(glass_test_pred_knn, glass_test$Type)

# random forest
glass_test_pred_rf <- predict(glass_rftune, glass_test)
confusionMatrix(glass_test_pred_rf, glass_test$Type)

# boosting
glass_test_pred_gb <- predict(glass_boosttune, glass_test)
confusionMatrix(glass_test_pred_gb, glass_test$Type)

1-0.796
1-0.815
```

Based on the TER, it appears that random forest has an estimated TER of 0.204% while the GBM had an estimated TER that was slightly better, at 0.185. All of the models seem to be having the most trouble with classifying `Type3` glass, but GBM does a slightly better job than the other two methods.

Next we took a look at the variable importance for the GBM.

```{r}
# boosting
set.seed(240)
gl_boost <- gbm(Type ~ ., data = glass_train,
                  distribution = "multinomial",
                  n.trees = 1000,
                  shrinkage = 0.05,
                  interaction.depth = 8,
                  n.minobsinnode = 8)
summary(gl_boost)
```
Magnesium appears to be the most important variable in the GBM. Calcium and refractive index also appear to be important factors in predicting glass types.

\newpage

## Conclusion 
```{r, include = FALSE}
# Do not put anything in this chunk. It is for instructions only.
# It will not show up in your rendered pdf document.

# Write a few sentences that summarize what you found, 
# addressing the problem at hand. 
```

Through our analysis, we found that the best classification model to classify the forensic glass samples was the gradient boosting model. While the the random forest took less time to run compared to the boosting model, it just wasn't as accurate. The GBM performed reasonably well, with a repeated, 10-fold cross validated AER of 0.241 and an estimated TER of 0.186.

Despite its strengths, the GBM still has room for improvement. While it can assist in preliminary investigations, its current accuracy is not sufficient for courtroom evidence. Perhaps with a larger data set, we could refine the model further and improve accuracy. Given the importance of accuracy in forensic classification, any model used in legal settings must meet the highest standards.

Additionally, our analysis highlighted that refractive index, along with magnesium and calcium content, are key factors in predicting glass type. This insight could guide future model development and forensic investigations.

